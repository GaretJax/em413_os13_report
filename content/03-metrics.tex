\lchapter[metrics]{Key Metrics}

% Identify the metrics by which you will measure the performance of the system (no more than 10). How do these relate to the stakeholder analysis you conducted in IAP? Next, downselect to the two most important metrics. Identify the sensitivity of each of the decisions to the two metrics, either by grouping them into “less sensitive” and “more sensitive”, or by evaluating the spread in metric values under different decision options. (1 slide or 1 page) [25%]

% Rubric
% Excellent (25 to >18.0 pts): Defined meaningful, measurable metrics in which to evaluate system performance, and provided clear traceability to stakeholder analysis. Assessed sensitivity of decisions based on the two selected metrics with clear connection from metric to stakeholder needs and mention of how the metrics could be validated or evaluated downstream. Strong method and arguments employed to evaluate sensitivity across the decisions.
% Very Good (18 to >9.0 pts): Metrics are solid and some traceability to stakeholders was shown. Method to assess sensitivity is adequate, but may lack rigor or detail. Sensitivity per decision was provided with minor inconsistencies.
% Good (9 to >0 pts): Metrics are not sufficient in measuring system performance, traceability to stakeholders is missing, or sensitivity analysis is incomplete or illogical. See TA feedback.

% Failure modes
% * Stakeholder map is not required as a deliverable. NOTE: It is not required to show the full stakeholder analysis; sufficient to show a summary to make the connection
% * Metrics are not measurable
% * A large list of metrics is provided but not refined
% * Metrics are co-variant
% * Sensitivity is confused with connectivity
% * Sensitivity of the variation across decision options is confused with the priority of one (of many) potential customers or technical sensitivity (accuracy/precision of a measurement device)
